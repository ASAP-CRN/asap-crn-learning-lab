{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cc8363",
   "metadata": {},
   "source": [
    "<p align=\"left\">\n",
    "  <img src=\"https://img.shields.io/badge/Research%20Mode-ON-4cbb17?style=for-the-badge\" alt=\"Research Mode\">\n",
    "</p>\n",
    "\n",
    "# 02 Â· Data Exploration â€” ASAP CRN Learning Lab  \n",
    "*A guided launchpad for your second ASAP-CRN workspace adventure.*\n",
    "\n",
    "Welcome to the **ASAP-CRN Learning Lab Pilot Workshop Series!**  \n",
    "\n",
    "This notebook walks you through the essentials of data inspection and preliminary analyses in **Verily Workbench**.\n",
    "\n",
    "> ðŸ’¡ **Tip:** Run each cell in order for the smoothest setup experience.  \n",
    "> You can always come back later to experiment and make it your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7edfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amaraalexander/miniconda3/envs/ASAP-CRN/bin/python\n"
     ]
    }
   ],
   "source": [
    "# setting up environment\n",
    "import sys\n",
    "print(sys.executable)\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1200)\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import scanpy as sc\n",
    "except ImportError as e:\n",
    "    print(\"Error -> \", e)\n",
    "    print(\"Installing scanpy\")\n",
    "    !conda install scanpy\n",
    "    import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f6f90",
   "metadata": {},
   "source": [
    "### 3. Building Dataset Paths\n",
    "\n",
    "Next, we define the path to the dataset of interest.  \n",
    "In this example, we are working with the **PMDBS singleâ€‘cell RNAâ€‘seq cohort** dataset:\n",
    "\n",
    "- **Workflow** â†’ `pmdbs_sc_rnaseq`  \n",
    "- **Team** â†’ `cohort`  \n",
    "- **Source** â†’ `pmdbs`  \n",
    "- **Type** â†’ `sc-rnaseq`  \n",
    "\n",
    "These components are combined to construct the bucket and dataset names.  \n",
    "We then set the path to the **cohort analysis outputs** and preview the available files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ddd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set general folder paths\n",
    "HOME = Path.home()\n",
    "WS_ROOT = HOME / \"workspace\"\n",
    "DATA_DIR = WS_ROOT / \"Data\"\n",
    "WS_FILES = WS_ROOT / \"ws_files\"\n",
    "\n",
    "if not WS_ROOT.exists():\n",
    "    print(f\"{WS_ROOT} doesn't exist. We need to remount our resources\")\n",
    "    !wb resource mount    \n",
    "\n",
    "print(\"Home directory:     \", HOME)\n",
    "print(\"Workspace root:     \", WS_ROOT)\n",
    "print(\"Data directory:     \", DATA_DIR)\n",
    "print(\"ws_files directory: \", WS_FILES)\n",
    "\n",
    "print(\"\\nContents of workspace root:\")\n",
    "for p in WS_ROOT.glob(\"*\"):\n",
    "    print(\" -\", p.name, \"/\" if p.is_dir() else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b1dc3",
   "metadata": {},
   "source": [
    "### 3. Building Dataset Paths\n",
    "\n",
    "Next, we define the path to the dataset of interest.  \n",
    "In this example, we are working with the **PMDBS singleâ€‘cell RNAâ€‘seq cohort** dataset:\n",
    "\n",
    "- **Workflow** â†’ `pmdbs_sc_rnaseq`  \n",
    "- **Team** â†’ `cohort`  \n",
    "- **Source** â†’ `pmdbs`  \n",
    "- **Type** â†’ `sc-rnaseq`  \n",
    "\n",
    "These components are combined to construct the bucket and dataset names.  \n",
    "We then set the path to the **cohort analysis outputs** and preview the available files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build and set path to desired dataset\n",
    "\n",
    "DATASETS_PATH = WS_ROOT / \"01_PMDBS_scRNAseq\"\n",
    "\n",
    "workflow       = \"pmdbs_sc_rnaseq\"\n",
    "dataset_team   = \"cohort\"\n",
    "dataset_source = \"pmdbs\"\n",
    "dataset_type   = \"sc-rnaseq\"\n",
    "\n",
    "bucket_name  = f\"asap-curated-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "dataset_name = f\"asap-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "\n",
    "dataset_path = DATASETS_PATH / bucket_name / workflow\n",
    "print(\"Dataset Path:\", dataset_path)\n",
    "cohort_analysis_path = dataset_path / \"cohort_analysis\"\n",
    "\n",
    "!ls  {cohort_analysis_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f61e3",
   "metadata": {},
   "source": [
    "### 4. Metadata Resources\n",
    "\n",
    "Alongside the dataset, we also define a path to the **release metadata resources**.  \n",
    "This folder contains tables describing samples, subjects, brain regions, and experimental conditions.  \n",
    "Previewing the contents helps us confirm which metadata files are available for integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292afbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define metadata folder path\n",
    "ds_metadata_path = WS_ROOT / \"release_resources/cohort-pmdbs-sc-rnaseq/metadata\"\n",
    "\n",
    "#preview contents\n",
    "!ls {ds_metadata_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106f9c7",
   "metadata": {},
   "source": [
    "### 5. Local Output Directory\n",
    "\n",
    "To keep our work organized, we create a local directory inside `ws_files` called `pilot_workshop_files`.  \n",
    "This is where weâ€™ll save any outputs (plots, tables, subsetted data) that we want to retain or share.  \n",
    "If the directory doesnâ€™t exist yet, we create it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a local path for workshop files\n",
    "local_data_path = WS_FILES / \"pilot_workshop_files\"\n",
    "\n",
    "# Create the directory if it doesn't already exist\n",
    "if not local_data_path.exists():\n",
    "    local_data_path.mkdir(parents=True)\n",
    "\n",
    "print(f\"Local data directory ready at: {local_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bb2fb",
   "metadata": {},
   "source": [
    "### 6. Loading Data\n",
    "\n",
    "We now bring in the curated dataset files:\n",
    "\n",
    "- **`asap-cohort.final_metadata.csv`** â†’ cellâ€‘level metadata table\n",
    "- **`asap-cohort.final.h5ad`** â†’ full AnnData object containing expression data and annotations  \n",
    "\n",
    "We copy these files into our local `pilot_workshop_files` directory (if not already present) and load them into memory.  \n",
    "The metadata CSV is read into a Pandas dataframe, while the `.h5ad` file is loaded as an AnnData object in backed mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the expected local path\n",
    "cell_metadata_local_path = local_data_path / f\"asap-{dataset_team}.final_metadata.csv\"\n",
    "if not cell_metadata_local_path.exists():\n",
    "    cell_metadata_og_path = cohort_analysis_path / f\"asap-{dataset_team}.final_metadata.csv\"\n",
    "    !cp {cell_metadata_og_path} {cell_metadata_local_path}\n",
    "\n",
    "# load the adata object\n",
    "cell_metadata_df = pd.read_csv(cell_metadata_local_path, low_memory=False)\n",
    "print(f\"We have loaded the cell_metadata for N={cell_metadata_df.shape[0]} cells\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fae7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata_local_path = local_data_path / f\"asap-{dataset_team}.final.h5ad\"\n",
    "\n",
    "# Check if the adata file already exists locally.\n",
    "if not adata_local_path.exists():\n",
    "    adata_cell_metadata_og_path = cohort_analysis_path / f\"asap-{dataset_team}.final.h5ad\"\n",
    "    !cp {adata_cell_metadata_og_path} {adata_local_path}\n",
    "\n",
    "adata = sc.read_h5ad(adata_local_path, backed=\"r\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c76199",
   "metadata": {},
   "source": [
    "### 7. Data Exploration\n",
    "\n",
    "With both metadata and anndata loaded, we can begin exploring the dataset. A key step is **merging datasetâ€‘level metadata into cellâ€‘level metadata**. This allows us to annotate each cell with experimental conditions and subject information, enabling richer analyses.\n",
    "\n",
    "Specifically, we combine:\n",
    "- **Sampleâ€‘level metadata** (`SAMPLE.csv`)  \n",
    "- **Subjectâ€‘level metadata** (`SUBJECT.csv`)  \n",
    "- **Brain sample metadata** (`PMDBS.csv`)  \n",
    "- **Experimental condition metadata** (`CONDITION.csv`)  \n",
    "\n",
    "From each table, we select only the relevant columns (IDs, demographics, brain regions, conditions) to keep the merged metadata concise and focused. This merged metadata will later allow us to subset the dataset (e.g., by diagnosis or brain region) and encode Parkinsonâ€™s disease state for downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample-level metadata\n",
    "SAMPLE = pd.read_csv(ds_metadata_path / \"SAMPLE.csv\", index_col=0)\n",
    "# subject-level metadata\n",
    "SUBJECT = pd.read_csv(ds_metadata_path / \"SUBJECT.csv\", index_col=0)\n",
    "#  brain-sample metadata\n",
    "PMDBS = pd.read_csv(ds_metadata_path / \"PMDBS.csv\", index_col=0)\n",
    "# experimental condition metadata\n",
    "CONDITION = pd.read_csv(ds_metadata_path / \"CONDITION.csv\", index_col=0)\n",
    "\n",
    "# Just take a few of the columns which we need\n",
    "sample_cols = [\n",
    "    \"ASAP_sample_id\",\n",
    "    \"ASAP_subject_id\",\n",
    "    \"ASAP_team_id\",\n",
    "    \"ASAP_dataset_id\",\n",
    "    \"replicate\",\n",
    "    \"condition_id\",\n",
    "]\n",
    "subject_cols = [\n",
    "    \"ASAP_subject_id\",\n",
    "    \"source_subject_id\",\n",
    "    \"sex\",\n",
    "    \"age_at_collection\",\n",
    "    \"primary_diagnosis\",\n",
    "]\n",
    "pmdbs_cols = [\n",
    "    \"ASAP_sample_id\",\n",
    "    \"brain_region\",\n",
    "    \"region_level_1\",\n",
    "    \"region_level_2\",\n",
    "    \"region_level_3\",\n",
    "]\n",
    "condition_cols = [\n",
    "    \"condition_id\",\n",
    "    \"intervention_name\",\n",
    "    \"intervention_id\",\n",
    "    \"protocol_id\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASAP-CRN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
